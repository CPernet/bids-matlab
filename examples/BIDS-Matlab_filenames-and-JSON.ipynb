{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create filenames, filepaths, and JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: function /home/remi/github/BIDS-matlab/examples/../+bids/+internal/warning.m shadows a built-in function\n",
      "warning: function /home/remi/github/BIDS-matlab/examples/../+bids/+internal/warning.m shadows a built-in function\n",
      "warning: function /home/remi/github/BIDS-matlab/examples/../+bids/+internal/warning.m shadows a built-in function\n",
      "warning: function /home/remi/github/BIDS-matlab/examples/../+bids/+internal/warning.m shadows a built-in function\n"
     ]
    }
   ],
   "source": [
    "% add bids-matlab to path\n",
    "addpath(fullfile(pwd, '..'));\n",
    "\n",
    "% TO DO: rename the bids.internal.warning function instead of silencing warnings\n",
    "warning('off','all');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialising a new BIDS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be useful when you are going to output your analysis or your data acquisition into a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      " Initialize dataset with README, description, folder structure...\r\n",
      "\r\n",
      " init(pth, folders, is_derivative, is_datalad_ds)\r\n",
      "\r\n",
      " (C) Copyright 2021 BIDS-MATLAB developers\r\n",
      "\r\n",
      "\r\n",
      "Additional help for built-in functions and operators is\r\n",
      "available in the online version of the manual.  Use the command\r\n",
      "'doc <topic>' to search the manual index.\r\n",
      "\r\n",
      "Help and information about Octave is also available on the WWW\r\n",
      "at http://www.octave.org and via the help@octave.org\r\n",
      "mailing list.\r\n"
     ]
    }
   ],
   "source": [
    "help bids.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives datasets have some extra info in their `dataset_description.json`.\n",
    "\n",
    "If you are going to curate the dataset with Datalad, you can also mention it and this will modify the README to add extra info about this (taken from the datalad handbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_derivative = true;\n",
    "is_datalad_ds = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = fullfile(pwd, 'dummy_ds');\n",
    "\n",
    "folders.subjects = {'01', '02'};\n",
    "folders.sessions = {'pre', 'post'};\n",
    "folders.modalities = {'anat', 'eeg'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids.init(pth, folders, is_derivative, is_datalad_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdummy_ds\u001b[00m\r\n",
      "├── \u001b[01;34m01\u001b[00m\r\n",
      "│   ├── \u001b[01;34mpost\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34manat\u001b[00m\r\n",
      "│   │   └── \u001b[01;34meeg\u001b[00m\r\n",
      "│   └── \u001b[01;34mpre\u001b[00m\r\n",
      "│       ├── \u001b[01;34manat\u001b[00m\r\n",
      "│       └── \u001b[01;34meeg\u001b[00m\r\n",
      "├── \u001b[01;34m02\u001b[00m\r\n",
      "│   ├── \u001b[01;34mpost\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34manat\u001b[00m\r\n",
      "│   │   └── \u001b[01;34meeg\u001b[00m\r\n",
      "│   └── \u001b[01;34mpre\u001b[00m\r\n",
      "│       ├── \u001b[01;34manat\u001b[00m\r\n",
      "│       └── \u001b[01;34meeg\u001b[00m\r\n",
      "├── CHANGES\r\n",
      "├── dataset_description.json\r\n",
      "└── README\r\n",
      "\r\n",
      "14 directories, 3 files\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tree dummy_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template README was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# README\r\n",
      "\r\n",
      "The README is usually the starting point for researchers using your data\r\n",
      "and serves as a guidepost for users of your data. A clear and informative\r\n",
      "README makes your data much more usable.\r\n",
      "\r\n",
      "In general you can include information in the README that is not captured by some other\r\n",
      "files in the BIDS dataset (dataset_description.json, events.tsv, ...).\r\n",
      "\r\n",
      "It can also be useful to also include information that might already be \r\n",
      "present in another file of the dataset but might be important for users to be aware of \r\n",
      "before preprocessing or analysing the data.\r\n",
      "\r\n",
      "If the README gets too long you have the possibility to create a `/doc` folder\r\n",
      "and add it to the `.bidsignore` file to make sure it is ignored by the BIDS validator.\r\n",
      "\r\n",
      "More info here: https://neurostars.org/t/where-in-a-bids-dataset-should-i-put-notes-about-individual-mri-acqusitions/17315/3\r\n",
      "\r\n",
      "## Details related to access to the data\r\n",
      "\r\n",
      "- [ ] Data user agreement\r\n",
      "\r\n",
      "If the dataset requires a data user agreement, link to the relevant information.\r\n",
      "\r\n",
      "- [ ] Contact person\r\n",
      "\r\n",
      "Indicate the name and contact details (email and ORCID) of the person responsible for additional information.\r\n",
      "\r\n",
      "- [ ] Practical information to access the data\r\n",
      "\r\n",
      "If there is any special information related to access rights or \r\n",
      "how to download the data make sure to include it. \r\n",
      "For example, if the dataset was curated using datalad, \r\n",
      "make sure to include the relevant section from the datalad handbook:\r\n",
      "http://handbook.datalad.org/en/latest/basics/101-180-FAQ.html#how-can-i-help-others-get-started-with-a-shared-dataset\r\n",
      "\r\n",
      "## Overview\r\n",
      "\r\n",
      "- [ ] Project name (if relevant)\r\n",
      "\r\n",
      "- [ ] Year(s) that the project ran\r\n",
      "\r\n",
      "If no `scans.tsv` is included, this could at least cover when the data acquisition \r\n",
      "starter and ended. Local time of day is particularly relevant to subject state.\r\n",
      "\r\n",
      "- [ ] Brief overview of the tasks in the experiment\r\n",
      "\r\n",
      "A paragraph giving an overview of the experiment. This should include the \r\n",
      "goals or purpose and a discussion about how the experiment tries to achieve\r\n",
      "these goals.\r\n",
      "\r\n",
      "- [ ] Description of the contents of the dataset\r\n",
      "\r\n",
      "An easy thing to add is the output of the bids-validator that describes what type of \r\n",
      "data and the number of subject one can expect to find in the dataset. \r\n",
      "\r\n",
      "- [ ] Independent variables\r\n",
      "\r\n",
      "A brief discussion of condition variables (sometimes called contrasts\r\n",
      "or independent variables) that were varied across the experiment.\r\n",
      "\r\n",
      "- [ ] Dependent variables\r\n",
      "\r\n",
      "A brief discussion of the response variables (sometimes called the\r\n",
      "dependent variables) that were measured and or calculated to assess\r\n",
      "the effects of varying the condition variables. This might also include\r\n",
      "questionnaires administered to assess behavioral aspects of the experiment.\r\n",
      "\r\n",
      "- [ ] Control variables\r\n",
      "\r\n",
      "A brief discussion of the control variables --- that is what aspects \r\n",
      "were explicitly controlled in this experiment. The control variables might \r\n",
      "include subject pool, environmental conditions, set up, or other things \r\n",
      "that were explicitly controlled.\r\n",
      "\r\n",
      "- [ ] Quality assessment of the data\r\n",
      "\r\n",
      "Provide a short summary of the quality of the data ideally with descriptive statistics if relevant\r\n",
      "and with a link to more comprehensive description (like with MRIQC) if possible.\r\n",
      "\r\n",
      "## Methods  \r\n",
      "\r\n",
      "### Subjects\r\n",
      "\r\n",
      "A brief sentence about the subject pool in this experiment.\r\n",
      "\r\n",
      "Remember that `Control` or `Patient` status should be defined in the `participants.tsv`\r\n",
      "using a group column.\r\n",
      "\r\n",
      "- [ ] Information about the recruitment procedure\r\n",
      "- [ ] Subject inclusion criteria (if relevant)\r\n",
      "- [ ] Subject exclusion criteria (if relevant)\r\n",
      " \r\n",
      "### Apparatus\r\n",
      "\r\n",
      "A summary of the equipment and environment setup for the\r\n",
      "experiment. For example, was the experiment performed in a shielded room\r\n",
      "with the subject seated in a fixed position.\r\n",
      "\r\n",
      "### Initial setup\r\n",
      "\r\n",
      "A summary of what setup was performed when a subject arrived.\r\n",
      "\r\n",
      "### Task organization\r\n",
      "\r\n",
      "How the tasks were organized for a session.\r\n",
      "This is particularly important because BIDS datasets usually have task data\r\n",
      "separated into different files.) \r\n",
      "\r\n",
      "- [ ] Was task order counter-balanced?\r\n",
      "- [ ] What other activities were interspersed between tasks?  \r\n",
      "\r\n",
      "- [ ] In what order were the tasks and other activities performed? \r\n",
      "\r\n",
      "### Task details\r\n",
      "\r\n",
      "As much detail as possible about the task and the events that were recorded. \r\n",
      "\r\n",
      "### Additional data acquired\r\n",
      "\r\n",
      "A brief indication of data other than the\r\n",
      "imaging data that was acquired as part of this experiment. In addition\r\n",
      "to data from other modalities and behavioral data, this might include\r\n",
      "questionnaires and surveys, swabs, and clinical information. Indicate\r\n",
      "the availability of this data.\r\n",
      "\r\n",
      "This is especially relevant if the data are not included in a `phenotype` folder.\r\n",
      "https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html#phenotypic-and-assessment-data\r\n",
      "\r\n",
      "### Experimental location\r\n",
      "\r\n",
      "This should include any additional information regarding the \r\n",
      "the geographical location and facility that cannot be included\r\n",
      "in the relevant json files.\r\n",
      "\r\n",
      "### Missing data\r\n",
      "\r\n",
      "Mention something if some participants are missing some aspects of the data.\r\n",
      "This can take the form of a processing log and/or abnormalities about the dataset. \r\n",
      "\r\n",
      "Some examples:\r\n",
      "\r\n",
      "- A brain lesion or defect only present in one participant\r\n",
      "- Some experimental conditions missing on a given run for a participant because\r\n",
      "  of some technical issue.\r\n",
      "- Any noticeable feature of the data for certain participants\r\n",
      "- Differences (even slight) in protocol for certain participants.\r\n",
      "\r\n",
      "### Notes\r\n",
      "\r\n",
      "Any additional information or pointers to information that\r\n",
      "might be helpful to users of the dataset. Include qualitative information \r\n",
      "related to how the data acquisition went.\r\n",
      "________________________________________________________________________________\r\n",
      "\r\n",
      "[![made-with-datalad](https://www.datalad.org/badges/made_with.svg)](https://datalad.org)\r\n",
      "\r\n",
      "## DataLad datasets and how to use them\r\n",
      "\r\n",
      "This repository is a [DataLad](https://www.datalad.org/) dataset. It provides\r\n",
      "fine-grained data access down to the level of individual files, and allows for\r\n",
      "tracking future updates. In order to use this repository for data retrieval,\r\n",
      "[DataLad](https://www.datalad.org/) is required. It is a free and\r\n",
      "open source command line tool, available for all major operating\r\n",
      "systems, and builds up on Git and [git-annex](https://git-annex.branchable.com/)\r\n",
      "to allow sharing, synchronizing, and version controlling collections of\r\n",
      "large files. You can find information on how to install DataLad at\r\n",
      "[handbook.datalad.org/en/latest/intro/installation.html](http://handbook.datalad.org/en/latest/intro/installation.html).\r\n",
      "\r\n",
      "### Get the dataset\r\n",
      "\r\n",
      "A DataLad dataset can be `cloned` by running\r\n",
      "\r\n",
      "```\r\n",
      "datalad clone <url>\r\n",
      "```\r\n",
      "\r\n",
      "Once a dataset is cloned, it is a light-weight directory on your local machine.\r\n",
      "At this point, it contains only small metadata and information on the\r\n",
      "identity of the files in the dataset, but not actual *content* of the\r\n",
      "(sometimes large) data files.\r\n",
      "\r\n",
      "### Retrieve dataset content\r\n",
      "\r\n",
      "After cloning a dataset, you can retrieve file contents by running\r\n",
      "\r\n",
      "```\r\n",
      "datalad get <path/to/directory/or/file>`\r\n",
      "```\r\n",
      "\r\n",
      "This command will trigger a download of the files, directories, or\r\n",
      "subdatasets you have specified.\r\n",
      "\r\n",
      "DataLad datasets can contain other datasets, so called *subdatasets*.\r\n",
      "If you clone the top-level dataset, subdatasets do not yet contain\r\n",
      "metadata and information on the identity of files, but appear to be\r\n",
      "empty directories. In order to retrieve file availability metadata in\r\n",
      "subdatasets, run\r\n",
      "\r\n",
      "```\r\n",
      "datalad get -n <path/to/subdataset>\r\n",
      "```\r\n",
      "\r\n",
      "Afterwards, you can browse the retrieved metadata to find out about\r\n",
      "subdataset contents, and retrieve individual files with `datalad get`.\r\n",
      "If you use `datalad get <path/to/subdataset>`, all contents of the\r\n",
      "subdataset will be downloaded at once.\r\n",
      "\r\n",
      "### Stay up-to-date\r\n",
      "\r\n",
      "DataLad datasets can be updated. The command `datalad update` will\r\n",
      "*fetch* updates and store them on a different branch (by default\r\n",
      "`remotes/origin/master`). Running\r\n",
      "\r\n",
      "```\r\n",
      "datalad update --merge\r\n",
      "```\r\n",
      "\r\n",
      "will *pull* available updates and integrate them in one go.\r\n",
      "\r\n",
      "### Find out what has been done\r\n",
      "\r\n",
      "DataLad datasets contain their history in the ``git log``.\r\n",
      "By running ``git log`` (or a tool that displays Git history) in the dataset or on\r\n",
      "specific files, you can find out what has been done to the dataset or to individual files\r\n",
      "by whom, and when.\r\n",
      "\r\n",
      "### More information\r\n",
      "\r\n",
      "More information on DataLad and how to use it can be found in the DataLad Handbook at\r\n",
      "[handbook.datalad.org](http://handbook.datalad.org/en/latest/index.html). The chapter\r\n",
      "\"DataLad datasets\" can help you to familiarize yourself with the concept of a dataset.\n"
     ]
    }
   ],
   "source": [
    "!cat dummy_ds/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"Name\": \"\",\r\n",
      "    \"BIDSVersion\": \"\",\r\n",
      "    \"DatasetType\": \"derivative\",\r\n",
      "    \"License\": \"\",\r\n",
      "    \"Authors\": \"\",\r\n",
      "    \"Acknowledgements\": \"\",\r\n",
      "    \"HowToAcknowledge\": \"\",\r\n",
      "    \"Funding\": \"\",\r\n",
      "    \"ReferencesAndLinks\": \"\",\r\n",
      "    \"DatasetDOI\": \"\",\r\n",
      "    \"HEDVersion\": \"\",\r\n",
      "    \"GeneratedBy\": [\r\n",
      "        {\r\n",
      "            \"Name\": \"\",\r\n",
      "            \"Version\": \"\",\r\n",
      "            \"Description\": \"\",\r\n",
      "            \"CodeURL\": \"\",\r\n",
      "            \"Container\": {\r\n",
      "                \"Type\": \"\",\r\n",
      "                \"Tag\": \"\"\r\n",
      "            }\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"SourceDatasets\": [\r\n",
      "        {\r\n",
      "            \"DOI\": \"\",\r\n",
      "            \"URL\": \"\",\r\n",
      "            \"Version\": \"\"\r\n",
      "        }\r\n",
      "    ]\r\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat dummy_ds/dataset_description.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Generating filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the `bids.create_filename` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      " Creates a BIDS compatible filename and can be used to create new names to rename files\r\n",
      "\r\n",
      " USAGE::\r\n",
      "\r\n",
      "   [filename, pth, json] = bids.create_filename(p)\r\n",
      "\r\n",
      " :param p:  specification of the filename to create, very similar to the output of\r\n",
      "                   ``bids.internal.parse_filename``\r\n",
      " :type  p:  structure\r\n",
      "\r\n",
      " Content of ``p``:\r\n",
      "\r\n",
      "   - ``p.suffix``        - required\r\n",
      "   - ``p.ext``           - extension (default: ``p.ext = ''``)\r\n",
      "   - ``p.entities``      - structure listing the entity-label pairs to compose the filename\r\n",
      "   - ``p.prefix``        - prefex to prepend (default: ``p.prefix = ''``)\r\n",
      "   - ``p.use_schema``    - bollean to check required entities for a given suffix,\r\n",
      "                           and reorder entities according to the BIDS schema.\r\n",
      "   - ``p.entity_order``  - user specified order in which to arranges the entities\r\n",
      "                           in the filename. Overrides ``p.use_schema``.\r\n",
      "\r\n",
      " If no entity order is specified and the filename creation is not based on the BIDS\r\n",
      " schema, then the filename will be created by concatenating the entity-label pairs\r\n",
      " found in the content of ``p.entities``.\r\n",
      "\r\n",
      " USAGE::\r\n",
      "\r\n",
      " [filename, pth, json] = bids.create_filename(p, file)\r\n",
      "\r\n",
      " :param file: file whose name has to be modified by the content of ``p``.\r\n",
      " :type file:  string\r\n",
      "\r\n",
      "\r\n",
      " (C) Copyright 2021 BIDS-MATLAB developers\r\n",
      "\r\n",
      "\r\n",
      "Additional help for built-in functions and operators is\r\n",
      "available in the online version of the manual.  Use the command\r\n",
      "'doc <topic>' to search the manual index.\r\n",
      "\r\n",
      "Help and information about Octave is also available on the WWW\r\n",
      "at http://www.octave.org and via the help@octave.org\r\n",
      "mailing list.\r\n"
     ]
    }
   ],
   "source": [
    "help bids.create_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_task-faceRecognition_run-02_bold.nii\r\n",
      "pth = sub-01/ses-test/func\r\n"
     ]
    }
   ],
   "source": [
    "p.suffix = 'bold';\n",
    "p.ext = '.nii';\n",
    "p.entities = struct( ...\n",
    "                  'sub', '01', ...\n",
    "                  'ses', 'test', ...\n",
    "                  'task', 'face recognition', ...\n",
    "                  'run', '02');\n",
    "\n",
    "[filename, pth] = bids.create_filename(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default this relies on the BIDS schema to know in which order the entities must go for a certain `suffix` type. This can also tell you if you are missing a required entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: The entity task cannot not be empty for the suffix bold\r\n",
      "error: called from\r\n",
      "    create_filename at line 69 column 7\r\n"
     ]
    }
   ],
   "source": [
    "p.suffix = 'bold';\n",
    "p.ext = '.nii';\n",
    "p.entities = struct( ...\n",
    "                  'sub', '01', ...\n",
    "                  'ses', 'test', ...\n",
    "                  'run', '02');\n",
    "\n",
    "[filename, pth] = bids.create_filename(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior can be turned off with the `use_schema` \"flag\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_run-02_bold.nii\r\n",
      "pth = sub-01/ses-test/func\r\n"
     ]
    }
   ],
   "source": [
    "p.suffix = 'bold';\n",
    "p.ext = '.nii';\n",
    "p.use_schema = false;\n",
    "p.entities = struct( ...\n",
    "                  'sub', '01', ...\n",
    "                  'ses', 'test', ...\n",
    "                  'run', '02');\n",
    "\n",
    "[filename, pth] = bids.create_filename(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can specify the order of the entities manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = run-02_sub-01_ses-test_bold.nii\r\n",
      "pth = sub-01/ses-test/func\r\n"
     ]
    }
   ],
   "source": [
    "p.suffix = 'bold';\n",
    "p.ext = '.nii';\n",
    "p.entity_order = {'run', 'sub', 'ses'};\n",
    "p.entities = struct( ...\n",
    "                  'sub', '01', ...\n",
    "                  'ses', 'test', ...\n",
    "                  'run', '02');\n",
    "\n",
    "[filename, pth] = bids.create_filename(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to modify the entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_task-faceRecognition_run-02_bold.nii\n",
      "filename = sub-02_ses-test_task-newTask_run-02_bold.nii\n",
      "pth = sub-02/ses-test/func\n"
     ]
    }
   ],
   "source": [
    "clear p\n",
    "filename = 'sub-01_ses-test_task-faceRecognition_run-02_bold.nii'\n",
    "p.entities = struct( ...\n",
    "                  'sub', '02', ...\n",
    "                  'task', 'new task');\n",
    "\n",
    "[filename, pth] = bids.create_filename(p, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An entity can also be removed from the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-02_task-newTask_run-02_bold.nii\r\n"
     ]
    }
   ],
   "source": [
    "p.entities = struct('ses', '');\n",
    "filename = bids.create_filename(p, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be useful to remove the prefix of some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_task-faceRecognition_run-02_bold.nii\r\n"
     ]
    }
   ],
   "source": [
    "filename = 'wuasub-01_ses-test_task-faceRecognition_run-02_bold.nii';\n",
    "\n",
    "p.prefix = '';\n",
    "\n",
    "filename = bids.create_filename(p, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating file names for derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can prove useful as this function will also provide youi with a dummy json that should accompany derivatives files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_task-faceRecognition_run-02_desc-preproc_bold.nii\r\n",
      "pth = sub-01/ses-test/func\r\n",
      "json =\r\n",
      "\r\n",
      "  scalar structure containing the fields:\r\n",
      "\r\n",
      "    filename = sub-01_ses-test_task-faceRecognition_run-02_desc-preproc_bold.json\r\n",
      "    content =\r\n",
      "\r\n",
      "      scalar structure containing the fields:\r\n",
      "\r\n",
      "        Description = RECOMMENDED\r\n",
      "        Sources = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = OPTIONAL\r\n",
      "          }\r\n",
      "        }\r\n",
      "        RawSources = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = OPTIONAL\r\n",
      "          }\r\n",
      "        }\r\n",
      "        SpatialReference = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = REQUIRED if no space entityor if non standard space RECOMMENDED otherwise\r\n",
      "          }\r\n",
      "        }\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "filename = 'sub-01_ses-test_task-faceRecognition_run-02_bold.nii';\n",
    "\n",
    "p.entities = struct('desc', 'preproc');\n",
    "p.use_schema = false;\n",
    "\n",
    "[filename, pth, json] = bids.create_filename(p, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of the JSON should adapt depending on the entities or suffix present in the output filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = sub-01_ses-test_res-hi_desc-preproc_mask.nii\r\n",
      "pth = sub-01/ses-test\r\n",
      "json =\r\n",
      "\r\n",
      "  scalar structure containing the fields:\r\n",
      "\r\n",
      "    filename = sub-01_ses-test_res-hi_desc-preproc_mask.json\r\n",
      "    content =\r\n",
      "\r\n",
      "      scalar structure containing the fields:\r\n",
      "\r\n",
      "        Description = RECOMMENDED\r\n",
      "        Sources = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = OPTIONAL\r\n",
      "          }\r\n",
      "        }\r\n",
      "        RawSources = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = REQUIRED\r\n",
      "          }\r\n",
      "        }\r\n",
      "        SpatialReference = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = REQUIRED if no space entityor if non standard space RECOMMENDED otherwise\r\n",
      "          }\r\n",
      "        }\r\n",
      "        Resolution = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] =\r\n",
      "\r\n",
      "              scalar structure containing the fields:\r\n",
      "\r\n",
      "                hi: 1x24 sq_string\r\n",
      "\r\n",
      "          }\r\n",
      "        }\r\n",
      "        Atlas = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = OPTIONAL\r\n",
      "          }\r\n",
      "        }\r\n",
      "        Type = \r\n",
      "        {\r\n",
      "          [1,1] = \r\n",
      "          {\r\n",
      "            [1,1] = OPTIONAL\r\n",
      "          }\r\n",
      "        }\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "filename = 'sub-01_ses-test__res-hi_desc-brain_mask.nii';\n",
    "\n",
    "p.entities = struct('desc', 'preproc');\n",
    "p.use_schema = false;\n",
    "\n",
    "[filename, pth, json] = bids.create_filename(p, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
